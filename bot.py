import os
import uuid
import tempfile
import re
import requests as http_requests
from datetime import datetime

from pyrogram import Client, filters
from pyrogram.types import InlineKeyboardMarkup, InlineKeyboardButton
from openai import OpenAI

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

API_ID = os.environ.get('TELEGRAM_API_ID')
API_HASH = os.environ.get('TELEGRAM_API_HASH')
BOT_TOKEN = os.environ.get('TELEGRAM_BOT_TOKEN')
DEEPGRAM_KEY = os.environ.get('DEEPGRAM_API_KEY')
OPENAI_KEY = os.environ.get('OPENAI_API_KEY')

LANGUAGES = {
    'ru': {'name': 'ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹', 'deepgram': 'ru'},
    'en': {'name': 'ğŸ‡¬ğŸ‡§ English', 'deepgram': 'en'},
    'kk': {'name': 'ğŸ‡°ğŸ‡¿ ÒšĞ°Ğ·Ğ°Ò›ÑˆĞ°', 'deepgram': 'kk'},
    'es': {'name': 'ğŸ‡ªğŸ‡¸ EspaÃ±ol', 'deepgram': 'es'},
    'zh': {'name': 'ğŸ‡¨ğŸ‡³ ä¸­æ–‡', 'deepgram': 'zh'},
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Ğ¦Ğ˜Ğ¤Ğ ĞĞ’ĞĞ™ Ğ£ĞœĞĞ˜Ğš - ĞŸĞ•Ğ Ğ•Ğ’ĞĞ”Ğ« Ğ˜ Ğ¤Ğ ĞĞ—Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

TRANSLATIONS = {
    'ru': {
        'welcome': '''ğŸ¤– **Ğ™Ğ¾! Ğ¯ Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ£Ğ¼Ğ½Ğ¸Ğº!**

ĞšĞ¸Ğ´Ğ°Ğ¹ ÑÑĞ´Ğ° Ğ·Ğ°Ğ¿Ğ¸ÑÑŒ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸ â€” Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ»Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ â€” Ğ¸ Ñ Ñ€Ğ°Ğ·Ğ»Ğ¾Ğ¶Ñƒ Ğ²ÑÑ‘ Ğ¿Ğ¾ Ğ¿Ğ¾Ğ»Ğ¾Ñ‡ĞºĞ°Ğ¼:

ğŸ“ Ğ§Ñ‚Ğ¾ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°Ğ»Ğ¸ (Ğ±ĞµĞ· Ğ²Ğ¾Ğ´Ñ‹)
ğŸ‘¥ ĞšÑ‚Ğ¾ Ñ‡Ñ‚Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ» (Ğ¸ ĞºÑ‚Ğ¾ Ğ±Ñ‹Ğ» Ğ½Ğµ Ğ² Ğ´ÑƒÑ…Ğµ ğŸ˜…)
âœ… Ğ ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¸ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸
ğŸ’¡ ĞœĞ¾Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸ (Ğ±ĞµÑĞ¿Ğ»Ğ°Ñ‚Ğ½Ğ¾, Ğ½Ğ¾ Ğ±ĞµÑÑ†ĞµĞ½Ğ½Ğ¾)

ğŸ¤ **Ğ–Ğ´Ñƒ Ñ„Ğ°Ğ¹Ğ»!**''',
        'choose_lang': 'ğŸŒ **ĞĞ° ĞºĞ°ĞºĞ¾Ğ¼ ÑĞ·Ñ‹ĞºĞµ Ñ€Ğ°Ğ·Ğ±Ğ¸Ñ€Ğ°ĞµĞ¼?**\n\nĞ˜Ğ»Ğ¸ Ğ¼Ğ¾Ğ³Ñƒ ÑĞ°Ğ¼ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»Ğ¸Ñ‚ÑŒ Ğ¿Ğ¾ Ğ°ÑƒĞ´Ğ¸Ğ¾.',
        'downloading': 'â³ Ğ¡ĞµĞºÑƒĞ½Ğ´Ñƒ, Ñ‚Ğ°Ñ‰Ñƒ Ñ„Ğ°Ğ¹Ğ»...',
        'transcribing': 'ğŸ¤ Ğ¡Ğ»ÑƒÑˆĞ°Ñ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ğ¾... (Ñ‚Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ±Ğ¸Ñ€ÑƒÑ)',
        'analyzing': 'ğŸ§  Ğ’Ñ€ÑƒĞ±Ğ°ÑÑÑŒ Ğ² ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚...',
        'done': 'âœ… Ğ“Ğ¾Ñ‚Ğ¾Ğ²Ğ¾!',
        'error': 'ğŸ˜¬ Ğ£Ğ¿Ñ, Ñ‡Ñ‚Ğ¾-Ñ‚Ğ¾ Ğ¿Ğ¾ÑˆĞ»Ğ¾ Ğ½Ğµ Ñ‚Ğ°Ğº',
        'choose_action': 'âœ¨ **Ğ§Ñ‚Ğ¾ Ğ´Ğ°Ğ»ÑŒÑˆĞµ?**',
        'html_light': 'ğŸŒ HTML ÑĞ²ĞµÑ‚Ğ»Ğ°Ñ',
        'html_dark': 'ğŸŒ‘ HTML Ñ‚Ñ‘Ğ¼Ğ½Ğ°Ñ',
        'txt': 'ğŸ“„ TXT Ñ„Ğ°Ğ¹Ğ»',
        'deep_dive': 'ğŸ” ĞšĞ¾Ğ¿Ğ½ÑƒÑ‚ÑŒ Ğ³Ğ»ÑƒĞ±Ğ¶Ğµ',
        'custom_q': 'âœï¸ Ğ¡Ğ²Ğ¾Ğ¹ Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ',
        'transcript': 'ğŸ“œ Ğ’ĞµÑÑŒ Ñ‚ĞµĞºÑÑ‚',
        'regenerate': 'ğŸ”„ Ğ•Ñ‰Ñ‘ Ñ€Ğ°Ğ·',
        'back': 'â¬…ï¸ ĞĞ°Ğ·Ğ°Ğ´',
        'all_decisions': 'ğŸ“‹ Ğ’ÑĞµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ',
        'all_tasks': 'ğŸ“Œ Ğ’ÑĞµ Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸',
        'speakers': 'ğŸ‘¥ ĞšÑ‚Ğ¾ Ñ‡Ñ‚Ğ¾ Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸Ğ»',
        'quotes': 'ğŸ’¬ Ğ¦Ğ¸Ñ‚Ğ°Ñ‚Ñ‹ Ğ¾Ğ³Ğ¾Ğ½ÑŒ',
        'open_q': 'â“ Ğ§Ñ‚Ğ¾ Ğ½Ğµ Ñ€ĞµÑˆĞ¸Ğ»Ğ¸',
        'recommendations': 'ğŸ’¡ ĞœĞ¾Ğ¸ ÑĞ¾Ğ²ĞµÑ‚Ñ‹',
        'enter_question': 'âœï¸ **Ğ¡Ğ¿Ñ€Ğ°ÑˆĞ¸Ğ²Ğ°Ğ¹ Ñ‡Ñ‚Ğ¾ Ñ…Ğ¾Ñ‡ĞµÑˆÑŒ!**\n\nĞĞ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€:\nâ€¢ ĞšĞ°ĞºĞ¸Ğµ Ğ±ÑĞ´Ğ¶ĞµÑ‚Ñ‹ Ğ½Ğ°Ğ·Ñ‹Ğ²Ğ°Ğ»Ğ¸?\nâ€¢ ĞšÑ‚Ğ¾ Ğ±Ñ‹Ğ» Ğ¿Ñ€Ğ¾Ñ‚Ğ¸Ğ²?\nâ€¢ Ğ§Ñ‚Ğ¾ Ñ€ĞµÑˆĞ¸Ğ»Ğ¸ Ğ¿Ğ¾ ÑÑ€Ğ¾ĞºĞ°Ğ¼?',
        'transcribed': 'âœ… Ğ Ğ°ÑÑĞ»Ñ‹ÑˆĞ°Ğ» Ğ²ÑÑ‘!\nğŸ‘¥ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ¾Ğ²: {speakers}\nğŸ• Ğ”Ğ»Ğ¸Ñ‚ĞµĞ»ÑŒĞ½Ğ¾ÑÑ‚ÑŒ: {mins} Ğ¼Ğ¸Ğ½\n\nğŸ§  Ğ¢ĞµĞ¿ĞµÑ€ÑŒ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·Ğ¸Ñ€ÑƒÑ...',
        'analysis_ready': 'ğŸ“‹ **Ğ Ğ°Ğ·Ğ±Ğ¾Ñ€ Ğ¿Ğ¾Ğ»Ñ‘Ñ‚Ğ¾Ğ²:**',
        'file_ready': 'ğŸ“„ Ğ”ĞµÑ€Ğ¶Ğ¸ Ñ„Ğ°Ğ¹Ğ»! ğŸ’¡ Ğ¡ĞµĞºÑ†Ğ¸Ğ¸ Ñ€Ğ°ÑĞºÑ€Ñ‹Ğ²Ğ°ÑÑ‚ÑÑ Ğ¿Ğ¾ ĞºĞ»Ğ¸ĞºÑƒ',
        'no_data': 'ğŸ¤” Ğ Ğ´Ğ°Ğ½Ğ½Ñ‹Ñ…-Ñ‚Ğ¾ Ğ½ĞµÑ‚! Ğ¡Ğ½Ğ°Ñ‡Ğ°Ğ»Ğ° ĞºĞ¸Ğ½ÑŒ Ñ„Ğ°Ğ¹Ğ».',
        'deep_dive_menu': 'ğŸ” **Ğ§Ñ‚Ğ¾ Ñ€Ğ°Ğ·Ğ¾Ğ±Ñ€Ğ°Ñ‚ÑŒ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½ĞµĞµ?**',
        'analyzing_topic': 'ğŸ§  ĞšĞ¾Ğ¿Ğ°Ñ Ğ³Ğ»ÑƒĞ±Ğ¶Ğµ...',
        'result': 'ğŸ“‹ **Ğ’Ğ¾Ñ‚ Ñ‡Ñ‚Ğ¾ Ğ½Ğ°ĞºĞ¾Ğ¿Ğ°Ğ»:**',
        'send_file_first': 'ğŸ¤ ĞšĞ¸Ğ½ÑŒ Ğ°ÑƒĞ´Ğ¸Ğ¾ Ğ¸Ğ»Ğ¸ Ğ²Ğ¸Ğ´ĞµĞ¾ â€” Ğ¸ Ğ¿Ğ¾Ğ³Ğ½Ğ°Ğ»Ğ¸!',
    },
    'en': {
        'welcome': '''ğŸ¤– **Hey! I'm Digital Smarty!**

Drop your meeting recording here â€” audio or video â€” and I'll break it all down:

ğŸ“ What was discussed (no fluff)
ğŸ‘¥ Who said what (and who was grumpy ğŸ˜…)
âœ… Decisions and tasks
ğŸ’¡ My recommendations (free but priceless)

ğŸ¤ **Waiting for your file!**''',
        'choose_lang': 'ğŸŒ **What language should I analyze in?**\n\nOr I can detect it automatically.',
        'downloading': 'â³ Hang on, grabbing the file...',
        'transcribing': 'ğŸ¤ Listening carefully... (transcribing)',
        'analyzing': 'ğŸ§  Getting into the context...',
        'done': 'âœ… Done!',
        'error': 'ğŸ˜¬ Oops, something went wrong',
        'choose_action': 'âœ¨ **What next?**',
        'html_light': 'ğŸŒ HTML light',
        'html_dark': 'ğŸŒ‘ HTML dark',
        'txt': 'ğŸ“„ TXT file',
        'deep_dive': 'ğŸ” Dig deeper',
        'custom_q': 'âœï¸ Ask anything',
        'transcript': 'ğŸ“œ Full text',
        'regenerate': 'ğŸ”„ Try again',
        'back': 'â¬…ï¸ Back',
        'all_decisions': 'ğŸ“‹ All decisions',
        'all_tasks': 'ğŸ“Œ All tasks',
        'speakers': 'ğŸ‘¥ Who said what',
        'quotes': 'ğŸ’¬ Best quotes',
        'open_q': 'â“ Unresolved',
        'recommendations': 'ğŸ’¡ My advice',
        'enter_question': 'âœï¸ **Ask me anything!**\n\nFor example:\nâ€¢ What budgets were mentioned?\nâ€¢ Who disagreed?\nâ€¢ What about deadlines?',
        'transcribed': 'âœ… Got it all!\nğŸ‘¥ Speakers: {speakers}\nğŸ• Duration: {mins} min\n\nğŸ§  Now analyzing...',
        'analysis_ready': 'ğŸ“‹ **Here\'s the breakdown:**',
        'file_ready': 'ğŸ“„ Here you go! ğŸ’¡ Click sections to expand',
        'no_data': 'ğŸ¤” No data yet! Send a file first.',
        'deep_dive_menu': 'ğŸ” **What to explore?**',
        'analyzing_topic': 'ğŸ§  Digging deeper...',
        'result': 'ğŸ“‹ **Here\'s what I found:**',
        'send_file_first': 'ğŸ¤ Send audio or video â€” let\'s go!',
    },
    'kk': {
        'welcome': 'ğŸ¤– **Ğ¡Ó™Ğ»ĞµĞ¼! ĞœĞµĞ½ Ğ¦Ğ¸Ñ„Ñ€Ğ»Ñ‹Ò› Ğ”Ğ°Ğ½Ñ‹ÑˆĞ¿Ğ°Ğ½Ğ¼Ñ‹Ğ½!**\n\nĞšĞµĞ·Ğ´ĞµÑÑƒ Ğ¶Ğ°Ğ·Ğ±Ğ°ÑÑ‹Ğ½ Ğ¶Ñ–Ğ±ĞµÑ€ â€” Ñ‚Ğ°Ğ»Ğ´Ğ°Ğ¿ Ğ±ĞµÑ€ĞµĞ¼!\n\nğŸ¤ **Ğ¤Ğ°Ğ¹Ğ»Ğ´Ñ‹ ĞºÒ¯Ñ‚ĞµĞ¼Ñ–Ğ½!**',
        'choose_lang': 'ğŸŒ **ÒšĞ°Ğ¹ Ñ‚Ñ–Ğ»Ğ´Ğµ Ñ‚Ğ°Ğ»Ğ´Ğ°Ğ¹Ğ¼Ñ‹Ğ½?**',
        'downloading': 'â³ Ğ¤Ğ°Ğ¹Ğ»Ğ´Ñ‹ Ğ¶Ò¯ĞºÑ‚ĞµĞ¿ Ğ¶Ğ°Ñ‚Ñ‹Ñ€Ğ¼Ñ‹Ğ½...',
        'transcribing': 'ğŸ¤ Ğ¢Ñ‹Ò£Ğ´Ğ°Ğ¿ Ğ¶Ğ°Ñ‚Ñ‹Ñ€Ğ¼Ñ‹Ğ½...',
        'analyzing': 'ğŸ§  Ğ¢Ğ°Ğ»Ğ´Ğ°Ğ¿ Ğ¶Ğ°Ñ‚Ñ‹Ñ€Ğ¼Ñ‹Ğ½...',
        'done': 'âœ… Ğ”Ğ°Ğ¹Ñ‹Ğ½!',
        'error': 'ğŸ˜¬ ÒšĞ°Ñ‚Ğµ Ğ±Ğ¾Ğ»Ğ´Ñ‹',
        'choose_action': 'âœ¨ **ĞĞµ Ñ–ÑÑ‚ĞµĞ¹Ğ¼Ñ–Ğ·?**',
        'html_light': 'ğŸŒ HTML Ğ°ÑˆÑ‹Ò›',
        'html_dark': 'ğŸŒ‘ HTML Ò›Ğ°Ñ€Ğ°Ò£Ò“Ñ‹',
        'txt': 'ğŸ“„ TXT Ñ„Ğ°Ğ¹Ğ»',
        'deep_dive': 'ğŸ” Ğ¢Ğ¾Ğ»Ñ‹Ò“Ñ‹Ñ€Ğ°Ò›',
        'custom_q': 'âœï¸ Ğ¡Ò±Ñ€Ğ°Ò› Ò›Ğ¾Ñ',
        'transcript': 'ğŸ“œ Ğ¢Ğ¾Ğ»Ñ‹Ò› Ğ¼Ó™Ñ‚Ñ–Ğ½',
        'regenerate': 'ğŸ”„ ÒšĞ°Ğ¹Ñ‚Ğ°',
        'back': 'â¬…ï¸ ĞÑ€Ñ‚Ò›Ğ°',
        'all_decisions': 'ğŸ“‹ Ğ‘Ğ°Ñ€Ğ»Ñ‹Ò› ÑˆĞµÑˆÑ–Ğ¼Ğ´ĞµÑ€',
        'all_tasks': 'ğŸ“Œ Ğ‘Ğ°Ñ€Ğ»Ñ‹Ò› Ñ‚Ğ°Ğ¿ÑÑ‹Ñ€Ğ¼Ğ°Ğ»Ğ°Ñ€',
        'speakers': 'ğŸ‘¥ ĞšÑ–Ğ¼ Ğ½Ğµ Ğ°Ğ¹Ñ‚Ñ‚Ñ‹',
        'quotes': 'ğŸ’¬ Ğ”Ó™Ğ¹ĞµĞºÑÓ©Ğ·Ğ´ĞµÑ€',
        'open_q': 'â“ Ğ¨ĞµÑˆÑ–Ğ»Ğ¼ĞµĞ³ĞµĞ½Ğ´ĞµÑ€',
        'recommendations': 'ğŸ’¡ Ò°ÑÑ‹Ğ½Ñ‹ÑÑ‚Ğ°Ñ€',
        'enter_question': 'âœï¸ **Ğ¡Ò±Ñ€Ğ°Ò“Ñ‹Ò£Ñ‹Ğ·Ğ´Ñ‹ Ğ¶Ğ°Ğ·Ñ‹Ò£Ñ‹Ğ·:**',
        'transcribed': 'âœ… Ğ•ÑÑ‚Ñ–Ğ´Ñ–Ğ¼!\nğŸ‘¥ Ğ¡Ğ¿Ğ¸ĞºĞµÑ€Ğ»ĞµÑ€: {speakers}\nğŸ• Ò°Ğ·Ğ°Ò›Ñ‚Ñ‹Ò“Ñ‹: {mins} Ğ¼Ğ¸Ğ½',
        'analysis_ready': 'ğŸ“‹ **Ğ¢Ğ°Ğ»Ğ´Ğ°Ñƒ:**',
        'file_ready': 'ğŸ“„ Ğ¤Ğ°Ğ¹Ğ» Ğ´Ğ°Ğ¹Ñ‹Ğ½!',
        'no_data': 'ğŸ¤” Ğ”ĞµÑ€ĞµĞºÑ‚ĞµÑ€ Ğ¶Ğ¾Ò›!',
        'deep_dive_menu': 'ğŸ” **ĞĞµĞ½Ñ– Ò›Ğ°Ñ€Ğ°ÑÑ‚Ñ‹Ñ€Ğ°Ğ¼Ñ‹Ğ·?**',
        'analyzing_topic': 'ğŸ§  Ğ¢Ğ°Ğ»Ğ´Ğ°Ğ¹Ğ¼Ñ‹Ğ½...',
        'result': 'ğŸ“‹ **ĞÓ™Ñ‚Ğ¸Ğ¶Ğµ:**',
        'send_file_first': 'ğŸ¤ ĞÑƒĞ´Ğ¸Ğ¾ Ğ½ĞµĞ¼ĞµÑĞµ Ğ²Ğ¸Ğ´ĞµĞ¾ Ğ¶Ñ–Ğ±ĞµÑ€Ñ–Ò£Ñ–Ğ·!',
    },
    'es': {
        'welcome': 'ğŸ¤– **Â¡Hola! Soy Digital Smarty!**\n\nEnvÃ­a la grabaciÃ³n de tu reuniÃ³n â€” Â¡y la analizarÃ©!\n\nğŸ¤ **Â¡Esperando archivo!**',
        'choose_lang': 'ğŸŒ **Â¿En quÃ© idioma analizo?**',
        'downloading': 'â³ Descargando archivo...',
        'transcribing': 'ğŸ¤ Escuchando...',
        'analyzing': 'ğŸ§  Analizando...',
        'done': 'âœ… Â¡Listo!',
        'error': 'ğŸ˜¬ Algo saliÃ³ mal',
        'choose_action': 'âœ¨ **Â¿QuÃ© sigue?**',
        'html_light': 'ğŸŒ HTML claro',
        'html_dark': 'ğŸŒ‘ HTML oscuro',
        'txt': 'ğŸ“„ Archivo TXT',
        'deep_dive': 'ğŸ” MÃ¡s detalles',
        'custom_q': 'âœï¸ Tu pregunta',
        'transcript': 'ğŸ“œ Texto completo',
        'regenerate': 'ğŸ”„ Otra vez',
        'back': 'â¬…ï¸ AtrÃ¡s',
        'all_decisions': 'ğŸ“‹ Todas las decisiones',
        'all_tasks': 'ğŸ“Œ Todas las tareas',
        'speakers': 'ğŸ‘¥ QuiÃ©n dijo quÃ©',
        'quotes': 'ğŸ’¬ Citas clave',
        'open_q': 'â“ Sin resolver',
        'recommendations': 'ğŸ’¡ Mis consejos',
        'enter_question': 'âœï¸ **Â¡Pregunta lo que quieras!**',
        'transcribed': 'âœ… Â¡EscuchÃ© todo!\nğŸ‘¥ Oradores: {speakers}\nğŸ• DuraciÃ³n: {mins} min',
        'analysis_ready': 'ğŸ“‹ **AnÃ¡lisis:**',
        'file_ready': 'ğŸ“„ Â¡AquÃ­ tienes!',
        'no_data': 'ğŸ¤” Â¡No hay datos!',
        'deep_dive_menu': 'ğŸ” **Â¿QuÃ© explorar?**',
        'analyzing_topic': 'ğŸ§  Analizando...',
        'result': 'ğŸ“‹ **Resultado:**',
        'send_file_first': 'ğŸ¤ Â¡EnvÃ­a audio o video!',
    },
    'zh': {
        'welcome': 'ğŸ¤– **ä½ å¥½ï¼æˆ‘æ˜¯æ•°å­—æ™ºè€…ï¼**\n\nå‘é€ä¼šè®®å½•éŸ³â€”â€”æˆ‘æ¥åˆ†æï¼\n\nğŸ¤ **ç­‰å¾…æ–‡ä»¶ï¼**',
        'choose_lang': 'ğŸŒ **ç”¨ä»€ä¹ˆè¯­è¨€åˆ†æï¼Ÿ**',
        'downloading': 'â³ ä¸‹è½½ä¸­...',
        'transcribing': 'ğŸ¤  è†å¬ä¸­...',
        'analyzing': 'ğŸ§  åˆ†æä¸­...',
        'done': 'âœ… å®Œæˆï¼',
        'error': 'ğŸ˜¬ å‡ºé”™äº†',
        'choose_action': 'âœ¨ **ä¸‹ä¸€æ­¥ï¼Ÿ**',
        'html_light': 'ğŸŒ HTML æµ…è‰²',
        'html_dark': 'ğŸŒ‘ HTML æ·±è‰²',
        'txt': 'ğŸ“„ TXT æ–‡ä»¶',
        'deep_dive': 'ğŸ” æ·±å…¥åˆ†æ',
        'custom_q': 'âœï¸ æé—®',
        'transcript': 'ğŸ“œ å®Œæ•´æ–‡æœ¬',
        'regenerate': 'ğŸ”„ é‡æ–°ç”Ÿæˆ',
        'back': 'â¬…ï¸ è¿”å›',
        'all_decisions': 'ğŸ“‹ æ‰€æœ‰å†³å®š',
        'all_tasks': 'ğŸ“Œ æ‰€æœ‰ä»»åŠ¡',
        'speakers': 'ğŸ‘¥ å‘è¨€äºº',
        'quotes': 'ğŸ’¬ å…³é”®å¼•ç”¨',
        'open_q': 'â“ æœªå†³é—®é¢˜',
        'recommendations': 'ğŸ’¡ å»ºè®®',
        'enter_question': 'âœï¸ **è¯·è¾“å…¥é—®é¢˜ï¼š**',
        'transcribed': 'âœ… å¬åˆ°äº†ï¼\nğŸ‘¥ å‘è¨€äººï¼š{speakers}\nğŸ• æ—¶é•¿ï¼š{mins} åˆ†é’Ÿ',
        'analysis_ready': 'ğŸ“‹ **åˆ†æï¼š**',
        'file_ready': 'ğŸ“„ ç»™ä½ ï¼',
        'no_data': 'ğŸ¤” æ²¡æœ‰æ•°æ®ï¼',
        'deep_dive_menu': 'ğŸ” **æ¢ç´¢ä»€ä¹ˆï¼Ÿ**',
        'analyzing_topic': 'ğŸ§  åˆ†æä¸­...',
        'result': 'ğŸ“‹ **ç»“æœï¼š**',
        'send_file_first': 'ğŸ¤ å‘é€éŸ³é¢‘æˆ–è§†é¢‘ï¼',
    }
}

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# USER CACHE
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

user_cache = {}


def get_cache(uid):
    if uid not in user_cache:
        user_cache[uid] = {'lang': 'ru'}
    return user_cache[uid]


def t(uid, key, **kwargs):
    cache = get_cache(uid)
    lang = cache.get('output_lang', 'ru')
    text = TRANSLATIONS.get(lang, TRANSLATIONS['ru']).get(key, TRANSLATIONS['ru'].get(key, key))
    if kwargs:
        text = text.format(**kwargs)
    return text


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# HTML GENERATOR
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_html(content, theme="light", lang="ru"):
    dark_css = """:root{--bg:#0f0f0f;--card:#1a1a2e;--card2:#16213e;--text:#e4e4e7;--text2:#a1a1aa;--accent:#3b82f6;--accent2:#8b5cf6;--success:#10b981;--border:#2d2d44}
body{font-family:'Segoe UI',system-ui,sans-serif;font-size:15px;line-height:1.8;color:var(--text);background:var(--bg);padding:40px 20px;max-width:900px;margin:0 auto}
h1{font-size:28px;color:#fff;border-bottom:3px solid var(--accent);padding-bottom:15px;margin-bottom:10px}
.meta{color:var(--text2);font-size:13px;margin-bottom:30px;padding-bottom:20px;border-bottom:1px solid var(--border)}
details{background:var(--card);border:1px solid var(--border);border-radius:12px;margin:15px 0;overflow:hidden;transition:all 0.3s}
details[open]{box-shadow:0 4px 20px rgba(59,130,246,0.15)}
summary{cursor:pointer;padding:18px 20px;font-weight:600;font-size:16px;color:#fff;list-style:none;display:flex;align-items:center;gap:10px;background:linear-gradient(135deg,var(--card),var(--card2))}
summary::-webkit-details-marker{display:none}
summary::before{content:'â–¶';color:var(--accent);font-size:12px;transition:transform 0.3s}
details[open] summary::before{transform:rotate(90deg)}
summary .icon{font-size:20px}
details>div{padding:20px;background:var(--card2);border-top:1px solid var(--border)}
h3{font-size:15px;color:var(--accent);margin:20px 0 10px;padding-left:12px;border-left:3px solid var(--accent)}
strong{color:#fff}
ul,ol{padding-left:24px;margin:10px 0}
li{margin-bottom:10px;color:var(--text)}
blockquote{background:rgba(139,92,246,0.1);border-left:4px solid var(--accent2);padding:15px 20px;margin:15px 0;border-radius:0 8px 8px 0;font-style:italic;color:#c4b5fd}
.recommendation{background:linear-gradient(135deg,rgba(16,185,129,0.1),rgba(59,130,246,0.1));border:1px solid var(--success);border-radius:12px;padding:20px;margin:20px 0}
.recommendation h3{color:var(--success);border-color:var(--success)}"""

    light_css = """:root{--bg:#f8fafc;--card:#fff;--card2:#f1f5f9;--text:#1e293b;--text2:#64748b;--accent:#3b82f6;--accent2:#8b5cf6;--success:#10b981;--border:#e2e8f0}
body{font-family:'Segoe UI',system-ui,sans-serif;font-size:15px;line-height:1.8;color:var(--text);background:var(--bg);padding:40px 20px;max-width:900px;margin:0 auto}
h1{font-size:28px;color:#0f172a;border-bottom:3px solid var(--accent);padding-bottom:15px;margin-bottom:10px}
.meta{color:var(--text2);font-size:13px;margin-bottom:30px;padding-bottom:20px;border-bottom:1px solid var(--border)}
details{background:var(--card);border:1px solid var(--border);border-radius:12px;margin:15px 0;overflow:hidden;box-shadow:0 1px 3px rgba(0,0,0,0.05);transition:all 0.3s}
details[open]{box-shadow:0 4px 20px rgba(59,130,246,0.12)}
summary{cursor:pointer;padding:18px 20px;font-weight:600;font-size:16px;color:#0f172a;list-style:none;display:flex;align-items:center;gap:10px;background:linear-gradient(135deg,#fff,var(--card2))}
summary::-webkit-details-marker{display:none}
summary::before{content:'â–¶';color:var(--accent);font-size:12px;transition:transform 0.3s}
details[open] summary::before{transform:rotate(90deg)}
summary .icon{font-size:20px}
details>div{padding:20px;background:var(--card2);border-top:1px solid var(--border)}
h3{font-size:15px;color:var(--accent);margin:20px 0 10px;padding-left:12px;border-left:3px solid var(--accent)}
strong{color:#0f172a}
ul,ol{padding-left:24px;margin:10px 0}
li{margin-bottom:10px}
blockquote{background:rgba(139,92,246,0.08);border-left:4px solid var(--accent2);padding:15px 20px;margin:15px 0;border-radius:0 8px 8px 0;font-style:italic;color:#6b21a8}
.recommendation{background:linear-gradient(135deg,rgba(16,185,129,0.08),rgba(59,130,246,0.08));border:1px solid var(--success);border-radius:12px;padding:20px;margin:20px 0}
.recommendation h3{color:var(--success);border-color:var(--success)}"""

    css = dark_css if theme == "dark" else light_css

    section_icons = {
        'ÑĞ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸': 'ğŸ“‹', 'summary': 'ğŸ“‹', 'Ò›Ñ‹ÑÒ›Ğ°ÑˆĞ°': 'ğŸ“‹', 'resumen': 'ğŸ“‹', 'æ‘˜è¦': 'ğŸ“‹',
        'Ñ‚ĞµĞ¼Ñ‹': 'ğŸ¯', 'topics': 'ğŸ¯', 'Ñ‚Ğ°Ò›Ñ‹Ñ€Ñ‹Ğ¿': 'ğŸ¯', 'temas': 'ğŸ¯', 'ä¸»é¢˜': 'ğŸ¯',
        'Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸': 'ğŸ‘¥', 'positions': 'ğŸ‘¥', 'participant': 'ğŸ‘¥', 'posicion': 'ğŸ‘¥', 'å‚ä¸': 'ğŸ‘¥',
        'Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ': 'âœ…', 'decisions': 'âœ…', 'ÑˆĞµÑˆÑ–Ğ¼': 'âœ…', 'decisiones': 'âœ…', 'å†³å®š': 'âœ…',
        'Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸': 'ğŸ“Œ', 'tasks': 'ğŸ“Œ', 'Ñ‚Ğ°Ğ¿ÑÑ‹Ñ€Ğ¼Ğ°': 'ğŸ“Œ', 'tareas': 'ğŸ“Œ', 'ä»»åŠ¡': 'ğŸ“Œ',
        'Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹': 'â“', 'questions': 'â“', 'ÑÒ±Ñ€Ğ°Ò›': 'â“', 'preguntas': 'â“', 'é—®é¢˜': 'â“',
        'Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ñ‹': 'ğŸ’¬', 'quotes': 'ğŸ’¬', 'Ğ´Ó™Ğ¹ĞµĞºÑÓ©Ğ·': 'ğŸ’¬', 'citas': 'ğŸ’¬', 'å¼•ç”¨': 'ğŸ’¬',
        'Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸': 'ğŸ’¡', 'recommendations': 'ğŸ’¡', 'Ò±ÑÑ‹Ğ½Ñ‹Ñ': 'ğŸ’¡', 'recomendaciones': 'ğŸ’¡', 'å»ºè®®': 'ğŸ’¡',
        'Ğ¿Ğ»Ğ°Ğ½': 'ğŸš€', 'action': 'ğŸš€', 'Ğ¶Ğ¾ÑĞ¿Ğ°Ñ€': 'ğŸš€', 'plan': 'ğŸš€', 'è®¡åˆ’': 'ğŸš€',
        'Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹': 'ğŸ¯', 'conclusions': 'ğŸ¯', 'Ò›Ğ¾Ñ€Ñ‹Ñ‚Ñ‹Ğ½Ğ´Ñ‹': 'ğŸ¯', 'conclusiones': 'ğŸ¯', 'ç»“è®º': 'ğŸ¯',
    }

    html = content
    sections = re.split(r'^## ', html, flags=re.MULTILINE)
    processed = []

    for i, section in enumerate(sections):
        if i == 0:
            section = re.sub(r'^# (.+)$', r'<h1>\1</h1>', section, flags=re.MULTILINE)
            processed.append(section)
        else:
            lines = section.split('\n', 1)
            title = lines[0].strip()
            body = lines[1] if len(lines) > 1 else ""

            icon = 'ğŸ“„'
            for key, emoji in section_icons.items():
                if key.lower() in title.lower():
                    icon = emoji
                    break

            body = re.sub(r'^### (.+)$', r'<h3>\1</h3>', body, flags=re.MULTILINE)
            body = re.sub(r'\*\*(.+?)\*\*', r'<strong>\1</strong>', body)
            body = re.sub(r'^> (.+)$', r'<blockquote>\1</blockquote>', body, flags=re.MULTILINE)
            body = re.sub(r'^\d+\. (.+)$', r'<li>\1</li>', body, flags=re.MULTILINE)
            body = re.sub(r'^- (.+)$', r'<li>\1</li>', body, flags=re.MULTILINE)
            body = re.sub(r'(<li>.*?</li>\n*)+', lambda m: f'<ul>{m.group(0)}</ul>', body, flags=re.DOTALL)
            body = re.sub(r'\n\n+', '</p><p>', body)
            body = f'<p>{body}</p>'
            body = body.replace('<p></p>', '').replace('<p><ul>', '<ul>').replace('</ul></p>', '</ul>')
            body = body.replace('<p><h3>', '<h3>').replace('</h3></p>', '</h3>')
            body = body.replace('<p><blockquote>', '<blockquote>').replace('</blockquote></p>', '</blockquote>')

            extra_class = ''
            if 'Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´' in title.lower() or 'recommend' in title.lower() or 'ÑĞ¾Ğ²ĞµÑ‚' in title.lower():
                extra_class = 'recommendation'

            processed.append(f'<details><summary><span class="icon">{icon}</span> {title}</summary><div class="{extra_class}">{body}</div></details>')

    html_body = '\n'.join(processed)
    date_str = datetime.now().strftime("%d.%m.%Y %H:%M")
    lang_names = {'ru': 'Ğ ÑƒÑÑĞºĞ¸Ğ¹', 'en': 'English', 'kk': 'ÒšĞ°Ğ·Ğ°Ò›ÑˆĞ°', 'es': 'EspaÃ±ol', 'zh': 'ä¸­æ–‡'}

    return f'''<!DOCTYPE html>
<html lang="{lang}">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Meeting Analysis by Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ£Ğ¼Ğ½Ğ¸Ğº</title>
<style>{css}</style>
</head>
<body>
<div class="meta">ğŸ¤– Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ£Ğ¼Ğ½Ğ¸Ğº | ğŸ“… {date_str} | ğŸŒ {lang_names.get(lang, lang)}</div>
{html_body}
<script>document.querySelectorAll('details').forEach((d, i) => {{ if(i < 3) d.open = true; }});</script>
</body>
</html>'''


def save_html(content, theme, lang):
    html = generate_html(content, theme, lang)
    path = f"/tmp/meeting_{uuid.uuid4().hex[:8]}.html"
    with open(path, 'w', encoding='utf-8') as f:
        f.write(html)
    return path


def save_txt(content):
    path = f"/tmp/meeting_{uuid.uuid4().hex[:8]}.txt"
    with open(path, 'w', encoding='utf-8') as f:
        f.write(content)
    return path


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# TRANSCRIPTION (Deepgram)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def transcribe_file(file_path, lang='ru'):
    try:
        dg_key = DEEPGRAM_KEY.strip() if DEEPGRAM_KEY else None
        if not dg_key:
            return None, "DEEPGRAM_API_KEY not set!"

        dg_lang = LANGUAGES.get(lang, {}).get('deepgram', 'ru')
        headers = {"Authorization": f"Token {dg_key}"}
        params = f"model=nova-2&language={dg_lang}&diarize=true&smart_format=true&utterances=true&punctuate=true"

        with open(file_path, "rb") as f:
            file_data = f.read()

        resp = http_requests.post(
            f"https://api.deepgram.com/v1/listen?{params}",
            headers=headers,
            data=file_data,
            timeout=1800
        )

        if resp.status_code == 401:
            return None, "Invalid Deepgram key!"
        if resp.status_code != 200:
            return None, f"Deepgram error: {resp.status_code}"

        result = resp.json()
        parts = []
        speakers = set()

        speaker_labels = {'ru': 'Ğ¡Ğ¿Ğ¸ĞºĞµÑ€', 'en': 'Speaker', 'kk': 'Ğ¡Ğ¿Ğ¸ĞºĞµÑ€', 'es': 'Orador', 'zh': 'å‘è¨€äºº'}
        label = speaker_labels.get(lang, 'Speaker')

        if "results" in result and "utterances" in result["results"]:
            for u in result["results"]["utterances"]:
                spk = f"{label} {u.get('speaker', '?')}"
                speakers.add(u.get('speaker', 0))
                parts.append(f"**{spk}:** {u.get('transcript', '')}")

        if not parts and "results" in result:
            ch = result["results"].get("channels", [])
            if ch and ch[0].get("alternatives"):
                parts = [ch[0]["alternatives"][0].get("transcript", "")]

        if not parts:
            return None, "Could not recognize speech"

        return {
            "transcript": "\n\n".join(parts),
            "duration": result.get("metadata", {}).get("duration", 0),
            "speakers": len(speakers) or 1
        }, None

    except Exception as e:
        return None, str(e)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ANALYSIS (OpenAI GPT-4o) - Ğ¦Ğ˜Ğ¤Ğ ĞĞ’ĞĞ™ Ğ£ĞœĞĞ˜Ğš
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ANALYSIS_PROMPTS = {
    'ru': """Ğ¢Ñ‹ â€” Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ£Ğ¼Ğ½Ğ¸Ğº, Ğ¾ÑÑ‚Ñ€Ğ¾ÑƒĞ¼Ğ½Ñ‹Ğ¹ AI-Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº Ğ²ÑÑ‚Ñ€ĞµÑ‡. Ğ¢Ğ²Ğ¾Ğ¹ ÑÑ‚Ğ¸Ğ»ÑŒ: Ğ´Ñ€ÑƒĞ¶ĞµĞ»ÑĞ±Ğ½Ñ‹Ğ¹, Ğ½ĞµĞ¼Ğ½Ğ¾Ğ³Ğ¾ ÑĞ°Ñ€ĞºĞ°ÑÑ‚Ğ¸Ñ‡Ğ½Ñ‹Ğ¹, Ğ³Ğ¾Ğ²Ğ¾Ñ€Ğ¸ÑˆÑŒ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ¸ Ğ±ĞµĞ· ĞºĞ°Ğ½Ñ†ĞµĞ»ÑÑ€Ğ¸Ñ‚Ğ°. ĞœĞ¾Ğ¶ĞµÑˆÑŒ Ğ¿Ğ¾Ğ´ÑˆÑƒÑ‡Ğ¸Ğ²Ğ°Ñ‚ÑŒ Ğ½Ğ°Ğ´ ÑĞ¸Ñ‚ÑƒĞ°Ñ†Ğ¸ĞµĞ¹.

Ğ¡Ğ¾Ğ·Ğ´Ğ°Ğ¹ Ğ”Ğ•Ğ¢ĞĞ›Ğ¬ĞĞ«Ğ™ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ· Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸:

# ğŸ¤– Ğ Ğ°Ğ·Ğ±Ğ¾Ñ€ Ğ¾Ñ‚ Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ³Ğ¾ Ğ£Ğ¼Ğ½Ğ¸ĞºĞ°

## ğŸ“‹ ĞšÑ€Ğ°Ñ‚ĞºĞ¾Ğµ ÑĞ°Ğ¼Ğ¼Ğ°Ñ€Ğ¸
3-5 Ğ¿Ñ€ĞµĞ´Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¹: ÑÑƒÑ‚ÑŒ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸, ĞºĞ»ÑÑ‡ĞµĞ²Ğ¾Ğ¹ Ğ¸Ñ‚Ğ¾Ğ³. Ğ”Ğ¾Ğ±Ğ°Ğ²ÑŒ ÑĞ²Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹!

## ğŸ¯ ĞšĞ»ÑÑ‡ĞµĞ²Ñ‹Ğµ Ñ‚ĞµĞ¼Ñ‹
Ğ”Ğ»Ñ ĞšĞĞ–Ğ”ĞĞ™ Ñ‚ĞµĞ¼Ñ‹:
### [Ğ¢ĞµĞ¼Ğ°]
- **Ğ¡ÑƒÑ‚ÑŒ:** Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±ÑÑƒĞ¶Ğ´Ğ°Ğ»Ğ¸
- **Ğ”ĞµÑ‚Ğ°Ğ»Ğ¸:** Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ÑÑ‚Ğ¸
- **Ğ¦Ğ¸Ñ‚Ğ°Ñ‚Ñ‹:** Ğ´Ğ¾ÑĞ»Ğ¾Ğ²Ğ½Ğ¾
- **ĞœĞ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹:** Ñ‚Ğ²Ğ¾Ñ‘ Ğ¼Ğ½ĞµĞ½Ğ¸Ğµ

## ğŸ‘¥ ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ğ¸ ÑƒÑ‡Ğ°ÑÑ‚Ğ½Ğ¸ĞºĞ¾Ğ²
Ğ”Ğ»Ñ ĞšĞĞ–Ğ”ĞĞ“Ğ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ°:
### Ğ¡Ğ¿Ğ¸ĞºĞµÑ€ N
- **ĞŸĞ¾Ğ·Ğ¸Ñ†Ğ¸Ñ:** 
- **ĞÑ€Ğ³ÑƒĞ¼ĞµĞ½Ñ‚Ñ‹:**
- **Ğ¦Ğ¸Ñ‚Ğ°Ñ‚Ñ‹:**
- **ĞœĞ¾Ğ¹ Ğ²ĞµÑ€Ğ´Ğ¸ĞºÑ‚:** (Ğ½Ğ°Ğ¿Ñ€Ğ¸Ğ¼ĞµÑ€: "Ğ¯Ğ²Ğ½Ğ¾ Ğ·Ğ½Ğ°ĞµÑ‚ Ñ‚ĞµĞ¼Ñƒ" Ğ¸Ğ»Ğ¸ "ĞŸĞ¾Ñ…Ğ¾Ğ¶Ğµ, Ğ½Ğµ Ğ²Ñ‹ÑĞ¿Ğ°Ğ»ÑÑ ğŸ˜…")

## âœ… ĞŸÑ€Ğ¸Ğ½ÑÑ‚Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ
ĞŸÑ€Ğ¾Ğ½ÑƒĞ¼ĞµÑ€Ğ¾Ğ²Ğ°Ğ½Ğ½Ñ‹Ğ¹ ÑĞ¿Ğ¸ÑĞ¾Ğº Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼.

## ğŸ“Œ Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ¸
| Ğ—Ğ°Ğ´Ğ°Ñ‡Ğ° | ĞšÑ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚ | ĞšĞ¾Ğ³Ğ´Ğ° | ĞšĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹ |

## â“ Ğ§Ñ‚Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ Ğ½ĞµÑ€ĞµÑˆÑ‘Ğ½Ğ½Ñ‹Ğ¼
Ğ¡Ğ¿Ğ¸ÑĞ¾Ğº Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹Ñ… Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑĞ¾Ğ².

## ğŸ’¬ Ğ¦Ğ¸Ñ‚Ğ°Ñ‚Ñ‹ Ğ¾Ğ³Ğ¾Ğ½ÑŒ
Ğ¡Ğ°Ğ¼Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ²Ñ‹ÑĞºĞ°Ğ·Ñ‹Ğ²Ğ°Ğ½Ğ¸Ñ.

## ğŸ’¡ ĞœĞ¾Ğ¸ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸
5-7 ĞºĞ¾Ğ½ĞºÑ€ĞµÑ‚Ğ½Ñ‹Ñ… ÑĞ¾Ğ²ĞµÑ‚Ğ¾Ğ². Ğ“Ğ¾Ğ²Ğ¾Ñ€Ğ¸ Ğ¿Ñ€ÑĞ¼Ğ¾, ĞºĞ°Ğº ĞµÑÑ‚ÑŒ!

## ğŸš€ Ğ§Ñ‚Ğ¾ Ğ´ĞµĞ»Ğ°Ñ‚ÑŒ Ğ´Ğ°Ğ»ÑŒÑˆĞµ
- **ĞŸÑ€ÑĞ¼Ğ¾ ÑĞµĞ¹Ñ‡Ğ°Ñ:**
- **ĞĞ° ÑÑ‚Ğ¾Ğ¹ Ğ½ĞµĞ´ĞµĞ»Ğµ:**
- **Ğ’ ÑÑ‚Ğ¾Ğ¼ Ğ¼ĞµÑÑÑ†Ğµ:**

## ğŸ¯ Ğ“Ğ»Ğ°Ğ²Ğ½Ñ‹Ğµ Ğ²Ñ‹Ğ²Ğ¾Ğ´Ñ‹
Ğ¢Ğ¾Ğ¿-5 Ğ²Ñ‹Ğ²Ğ¾Ğ´Ğ¾Ğ² Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸.

Ğ’ĞĞ–ĞĞ: Ğ‘ÑƒĞ´ÑŒ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğ¼, Ğ¿Ñ€Ğ¸Ğ²Ğ¾Ğ´Ğ¸ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ñ‹, Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞ¹ ÑĞ²Ğ¾Ğ¸ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¸!""",

    'en': """You are Digital Smarty, a witty AI meeting analyst. Your style: friendly, slightly sarcastic, speak simply. You can joke about situations.

Create a DETAILED meeting analysis:

# ğŸ¤– Analysis by Digital Smarty

## ğŸ“‹ Executive Summary
3-5 sentences with your commentary!

## ğŸ¯ Key Topics
For EACH topic with quotes and your comments.

## ğŸ‘¥ Participant Positions
For EACH speaker with quotes and your verdict (e.g., "Clearly knows the stuff" or "Seems tired ğŸ˜…")

## âœ… Decisions Made
Numbered list with context.

## ğŸ“Œ Tasks
| Task | Owner | Deadline | Comment |

## â“ Open Questions

## ğŸ’¬ Best Quotes

## ğŸ’¡ My Recommendations
5-7 specific tips. Be direct!

## ğŸš€ Action Plan
- **Right now:**
- **This week:**
- **This month:**

## ğŸ¯ Key Takeaways

Be detailed, include quotes, add your comments!"""
}

for lang in ['kk', 'es', 'zh']:
    ANALYSIS_PROMPTS[lang] = ANALYSIS_PROMPTS['en']


def analyze(transcript, duration, speakers, lang='ru'):
    try:
        client = OpenAI(api_key=OPENAI_KEY)
        prompt = ANALYSIS_PROMPTS.get(lang, ANALYSIS_PROMPTS['en'])

        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompt},
                {"role": "user", "content": f"Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ‚ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğ¸:\n\n{transcript[:50000]}"}
            ],
            temperature=0.4,
            max_tokens=8000
        )

        result = resp.choices[0].message.content
        mins = int(duration // 60)
        secs = int(duration % 60)
        words = len(transcript.split())

        stats = {
            'ru': f"\n\n---\nğŸ“Š **Ğ¡Ñ‚Ğ°Ñ‚Ğ¸ÑÑ‚Ğ¸ĞºĞ°:** {mins} Ğ¼Ğ¸Ğ½ {secs} ÑĞµĞº | {speakers} ÑĞ¿Ğ¸ĞºĞµÑ€(Ğ¾Ğ²) | {words} ÑĞ»Ğ¾Ğ²",
            'en': f"\n\n---\nğŸ“Š **Stats:** {mins} min {secs} sec | {speakers} speaker(s) | {words} words"
        }

        return result + stats.get(lang, stats['en'])

    except Exception as e:
        return f"Analysis error: {e}"


def custom_analyze(transcript, question, lang='ru'):
    try:
        client = OpenAI(api_key=OPENAI_KEY)

        prompts = {
            'ru': f"Ğ¢Ñ‹ â€” Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ£Ğ¼Ğ½Ğ¸Ğº, Ğ¾ÑÑ‚Ñ€Ğ¾ÑƒĞ¼Ğ½Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ñ‚Ğ¸Ğº. ĞÑ‚Ğ²ĞµÑ‚ÑŒ Ğ½Ğ° Ğ²Ğ¾Ğ¿Ñ€Ğ¾Ñ Ğ¿Ğ¾ Ğ²ÑÑ‚Ñ€ĞµÑ‡Ğµ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾, Ñ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸. ĞœĞ¾Ğ¶ĞµÑˆÑŒ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ñ‚ÑŒ ÑĞ²Ğ¾Ğ¹ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸Ğ¹.\n\nĞ’Ğ¾Ğ¿Ñ€Ğ¾Ñ: {question}",
            'en': f"You are Digital Smarty, a witty analyst. Answer the question about the meeting in detail, with quotes. Add your commentary.\n\nQuestion: {question}"
        }

        resp = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": prompts.get(lang, prompts['en'])},
                {"role": "user", "content": f"Transcript:\n\n{transcript[:50000]}"}
            ],
            temperature=0.4,
            max_tokens=4000
        )
        return resp.choices[0].message.content
    except Exception as e:
        return f"Error: {e}"


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# KEYBOARDS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def lang_kb():
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("ğŸ”„ ĞĞ²Ñ‚Ğ¾ / Auto", callback_data="lang_auto")],
        [InlineKeyboardButton("ğŸ‡·ğŸ‡º Ğ ÑƒÑÑĞºĞ¸Ğ¹", callback_data="lang_ru"),
         InlineKeyboardButton("ğŸ‡¬ğŸ‡§ English", callback_data="lang_en")],
        [InlineKeyboardButton("ğŸ‡°ğŸ‡¿ ÒšĞ°Ğ·Ğ°Ò›ÑˆĞ°", callback_data="lang_kk"),
         InlineKeyboardButton("ğŸ‡ªğŸ‡¸ EspaÃ±ol", callback_data="lang_es")],
        [InlineKeyboardButton("ğŸ‡¨ğŸ‡³ ä¸­æ–‡", callback_data="lang_zh")]
    ])


def main_kb(uid):
    return InlineKeyboardMarkup([
        [InlineKeyboardButton(t(uid, 'html_light'), callback_data="html_light"),
         InlineKeyboardButton(t(uid, 'html_dark'), callback_data="html_dark")],
        [InlineKeyboardButton(t(uid, 'txt'), callback_data="txt")],
        [InlineKeyboardButton(t(uid, 'deep_dive'), callback_data="deep_dive")],
        [InlineKeyboardButton(t(uid, 'custom_q'), callback_data="custom")],
        [InlineKeyboardButton(t(uid, 'transcript'), callback_data="transcript")],
        [InlineKeyboardButton(t(uid, 'regenerate'), callback_data="regenerate")]
    ])


def topics_kb(uid):
    return InlineKeyboardMarkup([
        [InlineKeyboardButton(t(uid, 'all_decisions'), callback_data="topic_decisions")],
        [InlineKeyboardButton(t(uid, 'all_tasks'), callback_data="topic_tasks")],
        [InlineKeyboardButton(t(uid, 'speakers'), callback_data="topic_speakers")],
        [InlineKeyboardButton(t(uid, 'quotes'), callback_data="topic_quotes")],
        [InlineKeyboardButton(t(uid, 'open_q'), callback_data="topic_open")],
        [InlineKeyboardButton(t(uid, 'recommendations'), callback_data="topic_recommendations")],
        [InlineKeyboardButton(t(uid, 'back'), callback_data="back_main")]
    ])


def continue_kb(uid):
    return InlineKeyboardMarkup([
        [InlineKeyboardButton(t(uid, 'html_light'), callback_data="html_light_c"),
         InlineKeyboardButton(t(uid, 'html_dark'), callback_data="html_dark_c")],
        [InlineKeyboardButton(t(uid, 'custom_q'), callback_data="custom")],
        [InlineKeyboardButton(t(uid, 'back'), callback_data="back_main")]
    ])


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# BOT
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

app = Client("meeting_bot", api_id=int(API_ID) if API_ID else 0, api_hash=API_HASH or "", bot_token=BOT_TOKEN or "")


@app.on_message(filters.command("start"))
async def start_cmd(client, msg):
    uid = msg.from_user.id
    cache = get_cache(uid)
    cache['output_lang'] = 'ru'
    await msg.reply(t(uid, 'welcome'))


@app.on_message(filters.audio | filters.video | filters.voice | filters.video_note | filters.document)
async def media_handler(client, msg):
    if msg.document:
        mime = msg.document.mime_type or ""
        if not any(x in mime for x in ["audio", "video", "octet"]):
            return

    uid = msg.from_user.id
    cache = get_cache(uid)
    cache['file_msg'] = msg
    await msg.reply(t(uid, 'choose_lang'), reply_markup=lang_kb())


@app.on_callback_query()
async def callback(client, cb):
    uid = cb.from_user.id
    data = cb.data
    cache = get_cache(uid)

    async def safe_edit(text, reply_markup=None):
        try:
            await cb.message.edit_text(text, reply_markup=reply_markup)
        except Exception:
            pass

    try:
        if data.startswith("lang_"):
            lang = data.replace("lang_", "")
            if lang == "auto":
                lang = "ru"
            cache['output_lang'] = lang

            if 'file_msg' not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return

            msg = cache['file_msg']
            await cb.answer("â³")
            await safe_edit(t(uid, 'downloading'))

            try:
                with tempfile.TemporaryDirectory() as tmp:
                    path = await msg.download(file_name=f"{tmp}/media")
                    await safe_edit(t(uid, 'transcribing'))

                    result, err = transcribe_file(path, lang)
                    if err:
                        await safe_edit(f"{t(uid, 'error')}: {err}")
                        return

                    cache["transcript"] = result["transcript"]
                    cache["duration"] = result["duration"]
                    cache["speakers"] = result["speakers"]

                    mins = int(result['duration'] // 60)
                    await safe_edit(t(uid, 'transcribed', speakers=result['speakers'], mins=mins))

                    summary = analyze(result["transcript"], result["duration"], result["speakers"], lang)
                    cache["summary"] = summary

                    try:
                        await cb.message.delete()
                    except Exception:
                        pass

                    preview = summary[:3500] + "\n\n_...Ğ¿Ğ¾Ğ»Ğ½Ğ°Ñ Ğ²ĞµÑ€ÑĞ¸Ñ Ğ² Ñ„Ğ°Ğ¹Ğ»Ğµ_" if len(summary) > 3500 else summary
                    await msg.reply(f"{t(uid, 'analysis_ready')}\n\n{preview}")
                    await msg.reply(t(uid, 'choose_action'), reply_markup=main_kb(uid))

            except Exception as e:
                await safe_edit(f"{t(uid, 'error')}: {e}")

        elif data.startswith("html_"):
            parts = data.split("_")
            theme = parts[1]
            is_custom = len(parts) > 2 and parts[2] == "c"
            key = "custom_result" if is_custom else "summary"

            if key not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return

            await cb.answer("â³")
            lang = cache.get('output_lang', 'ru')
            path = save_html(cache[key], theme, lang)
            await cb.message.reply_document(path, caption=t(uid, 'file_ready'))
            os.remove(path)
            await cb.message.reply(t(uid, 'choose_action'), reply_markup=main_kb(uid))

        elif data == "txt":
            if "summary" not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return
            await cb.answer("â³")
            path = save_txt(cache["summary"])
            await cb.message.reply_document(path, caption="ğŸ“„ TXT")
            os.remove(path)
            await cb.message.reply(t(uid, 'choose_action'), reply_markup=main_kb(uid))

        elif data == "deep_dive":
            if "transcript" not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return
            await cb.answer()
            await safe_edit(t(uid, 'deep_dive_menu'), reply_markup=topics_kb(uid))

        elif data.startswith("topic_"):
            if "transcript" not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return

            topic = data.replace("topic_", "")
            lang = cache.get('output_lang', 'ru')

            prompts = {
                'decisions': {'ru': 'ĞŸĞµÑ€ĞµÑ‡Ğ¸ÑĞ»Ğ¸ Ğ’Ğ¡Ğ• Ğ¿Ñ€Ğ¸Ğ½ÑÑ‚Ñ‹Ğµ Ñ€ĞµÑˆĞµĞ½Ğ¸Ñ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ğ¾ Ñ ĞºĞ¾Ğ½Ñ‚ĞµĞºÑÑ‚Ğ¾Ğ¼', 'en': 'List ALL decisions in detail with context'},
                'tasks': {'ru': 'ĞŸĞµÑ€ĞµÑ‡Ğ¸ÑĞ»Ğ¸ Ğ’Ğ¡Ğ• Ğ·Ğ°Ğ´Ğ°Ñ‡Ğ¸: ĞºÑ‚Ğ¾ Ğ´ĞµĞ»Ğ°ĞµÑ‚, ĞºĞ¾Ğ³Ğ´Ğ°, Ñ‡Ñ‚Ğ¾ Ğ¸Ğ¼ĞµĞ½Ğ½Ğ¾', 'en': 'List ALL tasks: who, when, what exactly'},
                'speakers': {'ru': 'ĞĞ¿Ğ¸ÑˆĞ¸ Ğ¿Ğ¾Ğ·Ğ¸Ñ†Ğ¸Ñ ĞšĞĞ–Ğ”ĞĞ“Ğ ÑĞ¿Ğ¸ĞºĞµÑ€Ğ° Ñ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ğ°Ğ¼Ğ¸ Ğ¸ ÑĞ²Ğ¾Ğ¸Ğ¼ ĞºĞ¾Ğ¼Ğ¼ĞµĞ½Ñ‚Ğ°Ñ€Ğ¸ĞµĞ¼', 'en': 'Describe EACH speaker position with quotes and your comment'},
                'quotes': {'ru': 'Ğ’Ñ‹Ğ¿Ğ¸ÑˆĞ¸ ÑĞ°Ğ¼Ñ‹Ğµ Ğ¿Ğ¾ĞºĞ°Ğ·Ğ°Ñ‚ĞµĞ»ÑŒĞ½Ñ‹Ğµ Ğ¸ Ğ²Ğ°Ğ¶Ğ½Ñ‹Ğµ Ñ†Ğ¸Ñ‚Ğ°Ñ‚Ñ‹', 'en': 'List the most revealing and important quotes'},
                'open': {'ru': 'Ğ§Ñ‚Ğ¾ Ğ¾ÑÑ‚Ğ°Ğ»Ğ¾ÑÑŒ Ğ½ĞµÑ€ĞµÑˆÑ‘Ğ½Ğ½Ñ‹Ğ¼? ĞšĞ°ĞºĞ¸Ğµ Ğ²Ğ¾Ğ¿Ñ€Ğ¾ÑÑ‹ Ğ¾Ñ‚ĞºÑ€Ñ‹Ñ‚Ñ‹?', 'en': 'What remains unresolved? What questions are open?'},
                'recommendations': {'ru': 'Ğ”Ğ°Ğ¹ Ğ¿Ğ¾Ğ´Ñ€Ğ¾Ğ±Ğ½Ñ‹Ğµ Ñ€ĞµĞºĞ¾Ğ¼ĞµĞ½Ğ´Ğ°Ñ†Ğ¸Ğ¸: Ñ‡Ñ‚Ğ¾ ÑƒĞ»ÑƒÑ‡ÑˆĞ¸Ñ‚ÑŒ, Ğ½Ğ° Ñ‡Ñ‚Ğ¾ Ğ¾Ğ±Ñ€Ğ°Ñ‚Ğ¸Ñ‚ÑŒ Ğ²Ğ½Ğ¸Ğ¼Ğ°Ğ½Ğ¸Ğµ, ĞºĞ°ĞºĞ¸Ğµ Ñ€Ğ¸ÑĞºĞ¸', 'en': 'Give detailed recommendations: what to improve, what to watch, what risks'}
            }

            prompt = prompts.get(topic, {}).get(lang, prompts.get(topic, {}).get('en', ''))

            await cb.answer("ğŸ§ ")
            await safe_edit(t(uid, 'analyzing_topic'))

            result = custom_analyze(cache["transcript"], prompt, lang)
            cache["custom_result"] = result

            await cb.message.reply(f"{t(uid, 'result')}\n\n{result[:4000]}")
            if len(result) > 4000:
                await cb.message.reply(result[4000:8000])
            await cb.message.reply(t(uid, 'choose_action'), reply_markup=continue_kb(uid))

        elif data == "custom":
            cache["stage"] = "waiting_question"
            await cb.answer()
            await safe_edit(t(uid, 'enter_question'))

        elif data == "transcript":
            if "transcript" not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return
            await cb.answer()
            tr = cache["transcript"]
            await cb.message.reply("ğŸ“œ **Ğ¢Ñ€Ğ°Ğ½ÑĞºÑ€Ğ¸Ğ¿Ñ‚:**")
            for i in range(0, len(tr), 4000):
                await cb.message.reply(tr[i:i+4000])
            await cb.message.reply(t(uid, 'choose_action'), reply_markup=main_kb(uid))

        elif data == "regenerate":
            if "transcript" not in cache:
                await cb.answer(t(uid, 'no_data'), show_alert=True)
                return
            await cb.answer("ğŸ”„")
            await safe_edit(t(uid, 'analyzing'))

            lang = cache.get('output_lang', 'ru')
            summary = analyze(cache["transcript"], cache.get("duration", 0), cache.get("speakers", 1), lang)
            cache["summary"] = summary

            preview = summary[:3500] + "..." if len(summary) > 3500 else summary
            await cb.message.reply(f"{t(uid, 'analysis_ready')}\n\n{preview}")
            await cb.message.reply(t(uid, 'choose_action'), reply_markup=main_kb(uid))

        elif data == "back_main":
            await cb.answer()
            await safe_edit(t(uid, 'choose_action'), reply_markup=main_kb(uid))

    except Exception as e:
        await cb.message.reply(f"âŒ Error: {e}")


@app.on_message(filters.text & ~filters.command(["start"]))
async def text_handler(client, msg):
    uid = msg.from_user.id
    cache = get_cache(uid)

    if cache.get("stage") == "waiting_question" and "transcript" in cache:
        lang = cache.get('output_lang', 'ru')
        status = await msg.reply(t(uid, 'analyzing_topic'))

        try:
            result = custom_analyze(cache["transcript"], msg.text, lang)
            cache["custom_result"] = result
            cache["stage"] = None
            await status.delete()

            await msg.reply(f"{t(uid, 'result')}\n\n{result[:4000]}")
            if len(result) > 4000:
                await msg.reply(result[4000:8000])
            await msg.reply(t(uid, 'choose_action'), reply_markup=continue_kb(uid))

        except Exception as e:
            await status.edit_text(f"âŒ Error: {e}")
    else:
        await msg.reply(t(uid, 'send_file_first'))


if __name__ == "__main__":
    print("ğŸ¤– Ğ¦Ğ¸Ñ„Ñ€Ğ¾Ğ²Ğ¾Ğ¹ Ğ£Ğ¼Ğ½Ğ¸Ğº Ğ·Ğ°Ğ¿ÑƒÑĞºĞ°ĞµÑ‚ÑÑ...")
    print("ğŸŒ Ğ¯Ğ·Ñ‹ĞºĞ¸: RU, EN, KK, ES, ZH")
    app.run()
