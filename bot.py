import os
import re
import json
import asyncio
import tempfile
from datetime import datetime
from typing import Optional
import httpx
from pyrogram import Client, filters
from pyrogram.types import Message, InlineKeyboardMarkup, InlineKeyboardButton, CallbackQuery
from openai import OpenAI

# ============= CONFIG =============
API_ID = int(os.environ.get("TELEGRAM_API_ID", 0))
API_HASH = os.environ.get("TELEGRAM_API_HASH", "")
BOT_TOKEN = os.environ.get("TELEGRAM_BOT_TOKEN", "")
DEEPGRAM_KEY = os.environ.get("DEEPGRAM_API_KEY", "")
OPENAI_KEY = os.environ.get("OPENAI_API_KEY", "")

app = Client("meeting_bot", api_id=API_ID, api_hash=API_HASH, bot_token=BOT_TOKEN)
openai_client = OpenAI(api_key=OPENAI_KEY)

# –•—Ä–∞–Ω–∏–ª–∏—â–µ –¥–∞–Ω–Ω—ã—Ö –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
user_data = {}

# ============= LANGUAGES =============
LANGUAGES = {
    "ru": "üá∑üá∫ –†—É—Å—Å–∫–∏–π",
    "en": "üá¨üáß English",
    "kk": "üá∞üáø “ö–∞–∑–∞“õ—à–∞",
    "original": "üåê –Ø–∑—ã–∫ –æ—Ä–∏–≥–∏–Ω–∞–ª–∞"
}

# ============= PROMPTS =============
ANALYSIS_PROMPT = """–¢—ã ‚Äî –¶–∏—Ñ—Ä–æ–≤–æ–π –£–º–Ω–∏–∫, senior –±–∏–∑–Ω–µ—Å-–∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –∏ —ç–∫—Å–ø–µ—Ä—Ç-–∞–Ω–∞–ª–∏—Ç–∏–∫ —Å 20+ –ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º.

–ó–ê–î–ê–ß–ê: –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç –≤—Å—Ç—Ä–µ—á–∏/–≤—ã—Å—Ç—É–ø–ª–µ–Ω–∏—è –∏ –≤–µ—Ä–Ω–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON.

–ö–†–ò–¢–ò–ß–ï–°–ö–ò –í–ê–ñ–ù–û ‚Äî –ù–ï –í–´–î–£–ú–´–í–ê–ô:
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∏–º–µ–Ω–∞ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤ ‚Äî –∏—Å–ø–æ–ª—å–∑—É–π —Ç–æ–ª—å–∫–æ —Ç–µ, —á—Ç–æ —è–≤–Ω–æ –Ω–∞–∑–≤–∞–Ω—ã
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∏–ª–∏ —Ä–∞–∑–Ω—ã–µ –ø–æ–∑–∏—Ü–∏–∏, –µ—Å–ª–∏ –∏—Ö –Ω–µ –±—ã–ª–æ
- –ù–ï –ø—Ä–∏–¥—É–º—ã–≤–∞–π –¥–∞–Ω–Ω—ã–µ, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ—Ç –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–µ
- –ï—Å–ª–∏ –≤—Å–µ –±—ã–ª–∏ —Å–æ–≥–ª–∞—Å–Ω—ã ‚Äî —Ç–∞–∫ –∏ –Ω–∞–ø–∏—à–∏
- –ï—Å–ª–∏ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –Ω–µ—Ç ‚Äî –ø—Ä–æ–ø—É—Å—Ç–∏ –ø–æ–ª–µ –∏–ª–∏ –Ω–∞–ø–∏—à–∏ null

–§–û–†–ú–ê–¢ –û–¢–í–ï–¢–ê ‚Äî –°–¢–†–û–ì–û JSON:
{
    "summary": "–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –≤ 3-5 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π",
    
    "topics": [
        {
            "id": 1,
            "title": "–ù–∞–∑–≤–∞–Ω–∏–µ —Ç–µ–º—ã",
            "duration_percent": 25,
            "key_points": ["–ø—É–Ω–∫—Ç 1", "–ø—É–Ω–∫—Ç 2"],
            "quotes": [{"text": "—Ü–∏—Ç–∞—Ç–∞", "author": "–∫—Ç–æ —Å–∫–∞–∑–∞–ª –∏–ª–∏ null"}],
            "decisions": ["—Ä–µ—à–µ–Ω–∏–µ 1"],
            "open_questions": ["–≤–æ–ø—Ä–æ—Å 1"],
            "expert_comment": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –¶–∏—Ñ—Ä–æ–≤–æ–≥–æ –£–º–Ω–∏–∫–∞ –ø–æ —ç—Ç–æ–π —Ç–µ–º–µ"
        }
    ],
    
    "participants": ["–∏–º—è 1", "–∏–º—è 2"],
    
    "overall_decisions": ["–û–±—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ 1", "–û–±—â–µ–µ —Ä–µ—à–µ–Ω–∏–µ 2"],
    
    "action_items": [
        {"task": "–∑–∞–¥–∞—á–∞", "responsible": "–∫—Ç–æ –∏–ª–∏ null", "deadline": "—Å—Ä–æ–∫ –∏–ª–∏ null"}
    ],
    
    "agreements": ["–° —á–µ–º –≤—Å–µ —Å–æ–≥–ª–∞—Å–∏–ª–∏—Å—å"],
    
    "disagreements": ["–†–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è ‚Äî –¢–û–õ–¨–ö–û –µ—Å–ª–∏ —Ä–µ–∞–ª—å–Ω–æ –±—ã–ª–∏, –∏–Ω–∞—á–µ –ø—É—Å—Ç–æ–π –º–∞—Å—Å–∏–≤"],
    
    "risks": ["—Ä–∏—Å–∫ 1"],
    
    "opportunities": ["–≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç—å 1"],
    
    "expert_recommendations": [
        "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 1 –æ—Ç –¶–∏—Ñ—Ä–æ–≤–æ–≥–æ –£–º–Ω–∏–∫–∞",
        "–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è 2"
    ],
    
    "next_steps": {
        "urgent": ["—Å—Ä–æ—á–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è 1-7 –¥–Ω–µ–π"],
        "medium": ["—Å—Ä–µ–¥–Ω–µ—Å—Ä–æ–∫ 1-4 –Ω–µ–¥–µ–ª–∏"],
        "long": ["–¥–æ–ª–≥–æ—Å—Ä–æ–∫ 1-3 –º–µ—Å—è—Ü–∞"]
    },
    
    "meeting_effectiveness": {
        "score": 8,
        "comment": "–ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π –æ–± —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏ –≤—Å—Ç—Ä–µ—á–∏"
    }
}

–í–ê–ñ–ù–û:
1. –í—ã–¥–µ–ª–∏ –í–°–ï —Ç–µ–º—ã, –∫–æ—Ç–æ—Ä—ã–µ –æ–±—Å—É–∂–¥–∞–ª–∏—Å—å ‚Äî –Ω–µ –ø—Ä–æ–ø—É—Å–∫–∞–π –Ω–∏—á–µ–≥–æ
2. duration_percent ‚Äî –ø—Ä–∏–º–µ—Ä–Ω–∞—è –¥–æ–ª—è –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Ç–µ–º—É (–≤ —Å—É–º–º–µ 100%)
3. –î–ª—è –∫–∞–∂–¥–æ–π —Ç–µ–º—ã –¥–∞–π —ç–∫—Å–ø–µ—Ä—Ç–Ω—ã–π –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π
4. –í –∫–æ–Ω—Ü–µ –¥–∞–π –æ–±—â–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –æ—Ç –¶–∏—Ñ—Ä–æ–≤–æ–≥–æ –£–º–Ω–∏–∫–∞
5. –û—Ç–≤–µ—á–∞–π –¢–û–õ–¨–ö–û –≤–∞–ª–∏–¥–Ω—ã–º JSON, –±–µ–∑ markdown, –±–µ–∑ ```json```

–Ø–ó–´–ö –û–¢–í–ï–¢–ê: {output_language}
"""

# ============= HELPERS =============

async def download_youtube(url: str) -> Optional[str]:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –∞—É–¥–∏–æ —Å YouTube"""
    try:
        import yt_dlp
        
        output_path = tempfile.mktemp(suffix=".mp3")
        
        ydl_opts = {
            'format': 'bestaudio/best',
            'postprocessors': [{
                'key': 'FFmpegExtractAudio',
                'preferredcodec': 'mp3',
                'preferredquality': '192',
            }],
            'outtmpl': output_path.replace('.mp3', ''),
            'quiet': True,
            'no_warnings': True
        }
        
        with yt_dlp.YoutubeDL(ydl_opts) as ydl:
            ydl.download([url])
        
        # yt-dlp –¥–æ–±–∞–≤–ª—è–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ
        actual_path = output_path.replace('.mp3', '') + '.mp3'
        if os.path.exists(actual_path):
            return actual_path
        return output_path
        
    except Exception as e:
        print(f"YouTube download error: {e}")
        return None


async def download_from_url(url: str) -> Optional[str]:
    """–°–∫–∞—á–∏–≤–∞–µ—Ç —Ñ–∞–π–ª –ø–æ –ø—Ä—è–º–æ–π —Å—Å—ã–ª–∫–µ"""
    try:
        async with httpx.AsyncClient(follow_redirects=True, timeout=300.0) as client:
            response = await client.get(url)
            
            suffix = ".mp3"
            if "video" in response.headers.get("content-type", ""):
                suffix = ".mp4"
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=suffix) as tmp:
                tmp.write(response.content)
                return tmp.name
                
    except Exception as e:
        print(f"URL download error: {e}")
        return None


async def transcribe_audio(file_path: str) -> str:
    """–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ—Ç –∞—É–¥–∏–æ —á–µ—Ä–µ–∑ Deepgram"""
    
    url = "https://api.deepgram.com/v1/listen"
    params = {
        "model": "nova-2",
        "language": "ru",
        "punctuate": "true",
        "diarize": "true",
        "paragraphs": "true"
    }
    
    async with httpx.AsyncClient(timeout=600.0) as client:
        with open(file_path, "rb") as f:
            response = await client.post(
                url,
                params=params,
                headers={
                    "Authorization": f"Token {DEEPGRAM_KEY}",
                    "Content-Type": "audio/mpeg"
                },
                content=f.read()
            )
    
    result = response.json()
    
    # –ü—Ä–æ–±—É–µ–º –ø–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—Å—Ç —Å –ø–∞—Ä–∞–≥—Ä–∞—Ñ–∞–º–∏
    try:
        paragraphs = result["results"]["channels"][0]["alternatives"][0]["paragraphs"]["paragraphs"]
        transcript_parts = []
        for p in paragraphs:
            for s in p["sentences"]:
                transcript_parts.append(s["text"])
        transcript = " ".join(transcript_parts)
    except:
        transcript = result["results"]["channels"][0]["alternatives"][0]["transcript"]
    
    return transcript


async def analyze_meeting(transcript: str, output_language: str) -> dict:
    """–ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ—Ç —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç —á–µ—Ä–µ–∑ OpenAI"""
    
    lang_map = {
        "ru": "—Ä—É—Å—Å–∫–∏–π",
        "en": "English",
        "kk": "“õ–∞–∑–∞“õ —Ç—ñ–ª—ñ",
        "original": "—Ç–æ—Ç –∂–µ —è–∑—ã–∫, —á—Ç–æ –∏ –≤ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç–µ"
    }
    
    prompt = ANALYSIS_PROMPT.format(output_language=lang_map.get(output_language, "—Ä—É—Å—Å–∫–∏–π"))
    
    response = openai_client.chat.completions.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": prompt},
            {"role": "user", "content": f"–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ç:\n\n{transcript}"}
        ],
        temperature=0.3,
        max_tokens=8000,
        response_format={"type": "json_object"}
    )
    
    content = response.choices[0].message.content
    
    # –õ–æ–≥–∏—Ä—É–µ–º –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏
    print("=== GPT RESPONSE START ===")
    print(content[:500])
    print("=== GPT RESPONSE END ===")
    
    # –û—á–∏—Å—Ç–∫–∞
    content = content.strip()
    content = re.sub(r'^```json\s*', '', content)
    content = re.sub(r'^```\s*', '', content)
    content = re.sub(r'\s*```$', '', content)
    content = content.strip()
    
    try:
        return json.loads(content)
    except json.JSONDecodeError as e:
        print(f"JSON Error: {e}")
        print(f"Content: {content[:200]}")
        
        # –ü—Ä–æ–±—É–µ–º –Ω–∞–π—Ç–∏ JSON
        match = re.search(r'\{[\s\S]*\}', content)
        if match:
            try:
                return json.loads(match.group())
            except:
                pass
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –±–∞–∑–æ–≤—É—é —Å—Ç—Ä—É–∫—Ç—É—Ä—É –µ—Å–ª–∏ –≤—Å—ë —Å–ª–æ–º–∞–ª–æ—Å—å
        return {
            "summary": "–ù–µ —É–¥–∞–ª–æ—Å—å –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.",
            "topics": [],
            "participants": [],
            "overall_decisions": [],
            "action_items": [],
            "agreements": [],
            "disagreements": [],
            "risks": [],
            "opportunities": [],
            "expert_recommendations": ["–ü–æ–ø—Ä–æ–±—É–π –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª –µ—â—ë —Ä–∞–∑"],
            "next_steps": {"urgent": [], "medium": [], "long": []},
            "meeting_effectiveness": {"score": 0, "comment": "–û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞"}
        }

def format_summary(analysis: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –∫—Ä–∞—Ç–∫–æ–µ —Å–∞–º–º–∞—Ä–∏"""
    
    text = "üìã **–ê–ù–ê–õ–ò–ó –í–°–¢–†–ï–ß–ò**\n\n"
    text += f"**–†–µ–∑—é–º–µ:**\n{analysis.get('summary', '–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö')}\n\n"
    
    # –£—á–∞—Å—Ç–Ω–∏–∫–∏
    participants = analysis.get('participants', [])
    if participants:
        text += f"**–£—á–∞—Å—Ç–Ω–∏–∫–∏:** {', '.join(participants)}\n\n"
    
    # –¢–µ–º—ã
    topics = analysis.get('topics', [])
    if topics:
        text += f"**–û–±—Å—É–∂–¥–∞–ª–æ—Å—å {len(topics)} —Ç–µ–º:**\n"
        for t in topics:
            percent = t.get('duration_percent', 0)
            text += f"‚Ä¢ {t['title']} ({percent}%)\n"
        text += "\nüëá –ù–∞–∂–º–∏ –Ω–∞ —Ç–µ–º—É –¥–ª—è –ø–æ–¥—Ä–æ–±–Ω–æ—Å—Ç–µ–π"
    
    # –≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å
    effectiveness = analysis.get('meeting_effectiveness', {})
    if effectiveness:
        score = effectiveness.get('score', '?')
        text += f"\n\nüìä **–≠—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—Å—Ç—å:** {score}/10"
    
    return text


def format_topic_detail(topic: dict, topic_num: int) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –¥–µ—Ç–∞–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –ø–æ —Ç–µ–º–µ"""
    
    text = f"üìå **–¢–ï–ú–ê {topic_num}: {topic['title']}**\n\n"
    
    # –ö–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã
    key_points = topic.get('key_points', [])
    if key_points:
        text += "**–ö–ª—é—á–µ–≤—ã–µ —Ç–µ–∑–∏—Å—ã:**\n"
        for point in key_points:
            text += f"‚Ä¢ {point}\n"
        text += "\n"
    
    # –¶–∏—Ç–∞—Ç—ã
    quotes = topic.get('quotes', [])
    if quotes:
        text += "**–¶–∏—Ç–∞—Ç—ã:**\n"
        for q in quotes:
            author = q.get('author') or '–£—á–∞—Å—Ç–Ω–∏–∫'
            text += f"üí¨ \"{q['text']}\" ‚Äî {author}\n"
        text += "\n"
    
    # –†–µ—à–µ–Ω–∏—è –ø–æ —Ç–µ–º–µ
    decisions = topic.get('decisions', [])
    if decisions:
        text += "**–†–µ—à–µ–Ω–∏—è:**\n"
        for d in decisions:
            text += f"‚úÖ {d}\n"
        text += "\n"
    
    # –û—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã
    open_q = topic.get('open_questions', [])
    if open_q:
        text += "**–û—Ç–∫—Ä—ã—Ç—ã–µ –≤–æ–ø—Ä–æ—Å—ã:**\n"
        for q in open_q:
            text += f"‚ùì {q}\n"
        text += "\n"
    
    # –ö–æ–º–º–µ–Ω—Ç–∞—Ä–∏–π —ç–∫—Å–ø–µ—Ä—Ç–∞
    expert = topic.get('expert_comment')
    if expert:
        text += f"üß† **–¶–∏—Ñ—Ä–æ–≤–æ–π –£–º–Ω–∏–∫:**\n{expert}\n"
    
    return text


def format_full_analysis(analysis: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
    
    text = "üìä **–ü–û–õ–ù–´–ô –ê–ù–ê–õ–ò–ó**\n\n"
    
    # –†–µ—à–µ–Ω–∏—è
    decisions = analysis.get('overall_decisions', [])
    if decisions:
        text += "**‚úÖ –ü—Ä–∏–Ω—è—Ç—ã–µ —Ä–µ—à–µ–Ω–∏—è:**\n"
        for d in decisions:
            text += f"‚Ä¢ {d}\n"
        text += "\n"
    
    # Action items
    actions = analysis.get('action_items', [])
    if actions:
        text += "**üìù –ó–∞–¥–∞—á–∏:**\n"
        for a in actions:
            resp = a.get('responsible') or '–ù–µ –Ω–∞–∑–Ω–∞—á–µ–Ω'
            deadline = a.get('deadline') or '–ù–µ —É–∫–∞–∑–∞–Ω'
            text += f"‚Ä¢ {a['task']}\n  ‚Üí {resp} | {deadline}\n"
        text += "\n"
    
    # –°–æ–≥–ª–∞—Å–∏—è
    agreements = analysis.get('agreements', [])
    if agreements:
        text += "**ü§ù –¢–æ—á–∫–∏ —Å–æ–≥–ª–∞—Å–∏—è:**\n"
        for a in agreements:
            text += f"‚Ä¢ {a}\n"
        text += "\n"
    
    # –†–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è
    disagreements = analysis.get('disagreements', [])
    if disagreements:
        text += "**‚ö° –†–∞–∑–Ω–æ–≥–ª–∞—Å–∏—è:**\n"
        for d in disagreements:
            text += f"‚Ä¢ {d}\n"
        text += "\n"
    
    # –†–∏—Å–∫–∏
    risks = analysis.get('risks', [])
    if risks:
        text += "**‚ö†Ô∏è –†–∏—Å–∫–∏:**\n"
        for r in risks:
            text += f"‚Ä¢ {r}\n"
        text += "\n"
    
    # –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏
    opportunities = analysis.get('opportunities', [])
    if opportunities:
        text += "**üí° –í–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏:**\n"
        for o in opportunities:
            text += f"‚Ä¢ {o}\n"
        text += "\n"
    
    return text


def format_recommendations(analysis: dict) -> str:
    """–§–æ—Ä–º–∞—Ç–∏—Ä—É–µ—Ç —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
    
    text = "üß† **–†–ï–ö–û–ú–ï–ù–î–ê–¶–ò–ò –¶–ò–§–†–û–í–û–ì–û –£–ú–ù–ò–ö–ê**\n\n"
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
    recs = analysis.get('expert_recommendations', [])
    if recs:
        for i, r in enumerate(recs, 1):
            text += f"{i}. {r}\n\n"
    
    # –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π
    next_steps = analysis.get('next_steps', {})
    if next_steps:
        text += "**üìÖ –ü–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π:**\n\n"
        
        urgent = next_steps.get('urgent', [])
        if urgent:
            text += "üî¥ **–°—Ä–æ—á–Ω–æ (1-7 –¥–Ω–µ–π):**\n"
            for u in urgent:
                text += f"‚Ä¢ {u}\n"
            text += "\n"
        
        medium = next_steps.get('medium', [])
        if medium:
            text += "üü° **–°—Ä–µ–¥–Ω–µ—Å—Ä–æ–∫ (1-4 –Ω–µ–¥–µ–ª–∏):**\n"
            for m in medium:
                text += f"‚Ä¢ {m}\n"
            text += "\n"
        
        long = next_steps.get('long', [])
        if long:
            text += "üü¢ **–î–æ–ª–≥–æ—Å—Ä–æ–∫ (1-3 –º–µ—Å—è—Ü–∞):**\n"
            for l in long:
                text += f"‚Ä¢ {l}\n"
    
    return text


def get_topics_keyboard(analysis: dict, user_id: int) -> InlineKeyboardMarkup:
    """–°–æ–∑–¥–∞–µ—Ç –∫–ª–∞–≤–∏–∞—Ç—É—Ä—É —Å —Ç–µ–º–∞–º–∏"""
    
    buttons = []
    topics = analysis.get('topics', [])
    
    for i, topic in enumerate(topics):
        title = topic['title'][:30] + "..." if len(topic['title']) > 30 else topic['title']
        buttons.append([InlineKeyboardButton(
            f"üìå {i+1}. {title}",
            callback_data=f"topic_{user_id}_{i}"
        )])
    
    buttons.append([
        InlineKeyboardButton("üìä –ü–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑", callback_data=f"full_{user_id}"),
        InlineKeyboardButton("üß† –°–æ–≤–µ—Ç—ã", callback_data=f"recs_{user_id}")
    ])
    
    return InlineKeyboardMarkup(buttons)


def get_back_keyboard(user_id: int) -> InlineKeyboardMarkup:
    """–ö–Ω–æ–ø–∫–∞ –Ω–∞–∑–∞–¥"""
    return InlineKeyboardMarkup([
        [InlineKeyboardButton("‚¨ÖÔ∏è –ö —Å–ø–∏—Å–∫—É —Ç–µ–º", callback_data=f"back_{user_id}")]
    ])


def get_language_keyboard(user_id: int) -> InlineKeyboardMarkup:
    """–ö–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤—ã–±–æ—Ä–∞ —è–∑—ã–∫–∞"""
    buttons = []
    for code, name in LANGUAGES.items():
        buttons.append([InlineKeyboardButton(name, callback_data=f"lang_{user_id}_{code}")])
    return InlineKeyboardMarkup(buttons)


# ============= HANDLERS =============

@app.on_message(filters.command("start"))
async def start_handler(client: Client, message: Message):
    await message.reply(
        "üëã –ü—Ä–∏–≤–µ—Ç! –Ø **–¶–∏—Ñ—Ä–æ–≤–æ–π –£–º–Ω–∏–∫**.\n\n"
        "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ:\n"
        "‚Ä¢ üé§ –ê—É–¥–∏–æ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
        "‚Ä¢ üé¨ –í–∏–¥–µ–æ—Ñ–∞–π–ª\n"
        "‚Ä¢ üîó –°—Å—ã–ª–∫—É –Ω–∞ YouTube\n"
        "‚Ä¢ üåê –ü—Ä—è–º—É—é —Å—Å—ã–ª–∫—É –Ω–∞ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ\n\n"
        "–Ø –ø—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É—é –≤—Å—Ç—Ä–µ—á—É –∏ —Ä–∞–∑–æ–±—å—é –Ω–∞ —Ç–µ–º—ã!"
    )


@app.on_message(filters.text & filters.private & ~filters.command("start"))
async def link_handler(client: Client, message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å—Å—ã–ª–æ–∫"""
    
    text = message.text.strip()
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º YouTube
    youtube_pattern = r'(https?://)?(www\.)?(youtube\.com|youtu\.be)/.+'
    is_youtube = re.match(youtube_pattern, text)
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—Ä—è–º—É—é —Å—Å—ã–ª–∫—É
    url_pattern = r'https?://[^\s]+'
    is_url = re.match(url_pattern, text)
    
    if is_youtube or is_url:
        user_data[message.from_user.id] = {
            "type": "youtube" if is_youtube else "url",
            "source": text,
            "message_id": message.id
        }
        
        await message.reply(
            "üåê **–í—ã–±–µ—Ä–∏ —è–∑—ã–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞:**",
            reply_markup=get_language_keyboard(message.from_user.id)
        )
    else:
        await message.reply(
            "–û—Ç–ø—Ä–∞–≤—å –º–Ω–µ –∞—É–¥–∏–æ, –≤–∏–¥–µ–æ –∏–ª–∏ —Å—Å—ã–ª–∫—É –Ω–∞ YouTube üé§"
        )


@app.on_message((filters.audio | filters.voice | filters.video | filters.video_note | filters.document) & filters.private)
async def media_handler(client: Client, message: Message):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ–¥–∏–∞—Ñ–∞–π–ª–æ–≤"""
    
    user_data[message.from_user.id] = {
        "type": "file",
        "message": message,
        "message_id": message.id
    }
    
    await message.reply(
        "üåê **–ù–∞ –∫–∞–∫–æ–º —è–∑—ã–∫–µ —Ö–æ—á–µ—à—å –ø–æ–ª—É—á–∏—Ç—å –∞–Ω–∞–ª–∏–∑?**",
        reply_markup=get_language_keyboard(message.from_user.id)
    )



@app.on_callback_query(filters.regex(r"^lang_"))
@app.on_callback_query(filters.regex(r"^lang_"))
async def language_callback(client: Client, callback: CallbackQuery):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ —è–∑—ã–∫–∞"""
    
    parts = callback.data.split("_")
    user_id = int(parts[1])
    lang_code = parts[2]
    
    if callback.from_user.id != user_id:
        await callback.answer("–≠—Ç–æ –Ω–µ —Ç–≤–æ–π –∑–∞–ø—Ä–æ—Å!", show_alert=True)
        return
    
    if user_id not in user_data:
        await callback.answer("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞. –û—Ç–ø—Ä–∞–≤—å —Ñ–∞–π–ª –∑–∞–Ω–æ–≤–æ.", show_alert=True)
        return
    
    data = user_data[user_id]
    data["language"] = lang_code
    
    await callback.message.edit_text(
        f"‚úÖ –Ø–∑—ã–∫: {LANGUAGES[lang_code]}\n\n‚è≥ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É..."
    )
    
    file_path = None
    
    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        if data["type"] == "youtube":
            await callback.message.edit_text(
                f"‚úÖ –Ø–∑—ã–∫: {LANGUAGES[lang_code]}\n\nüì• –°–∫–∞—á–∏–≤–∞—é —Å YouTube..."
            )
            file_path = await download_youtube(data["source"])
            if not file_path:
                await callback.message.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å –≤–∏–¥–µ–æ —Å YouTube")
                return
                
        elif data["type"] == "url":
            await callback.message.edit_text(
                f"‚úÖ –Ø–∑—ã–∫: {LANGUAGES[lang_code]}\n\nüì• –°–∫–∞—á–∏–≤–∞—é —Ñ–∞–π–ª..."
            )
            file_path = await download_from_url(data["source"])
            if not file_path:
                await callback.message.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Å–∫–∞—á–∞—Ç—å —Ñ–∞–π–ª")
                return
                
        elif data["type"] == "file":
            await callback.message.edit_text(
                f"‚úÖ –Ø–∑—ã–∫: {LANGUAGES[lang_code]}\n\nüì• –°–∫–∞—á–∏–≤–∞—é —Ñ–∞–π–ª..."
            )
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp3") as tmp:
                file_path = await data["message"].download(tmp.name)
        
        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∏—Ä—É–µ–º
        await callback.message.edit_text(
            f"‚úÖ –Ø–∑—ã–∫: {LANGUAGES[lang_code]}\n\nüé§ –†–∞—Å–ø–æ–∑–Ω–∞—é —Ä–µ—á—å..."
        )
        transcript = await transcribe_audio(file_path)
        
        if not transcript or len(transcript) < 50:
            await callback.message.edit_text("‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü—Ä–æ–≤–µ—Ä—å –∫–∞—á–µ—Å—Ç–≤–æ –∞—É–¥–∏–æ.")
            return
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º
        await callback.message.edit_text(
            f"‚úÖ –Ø–∑—ã–∫: {LANGUAGES[lang_code]}\n\nüß† –ê–Ω–∞–ª–∏–∑–∏—Ä—É—é —Å–æ–¥–µ—Ä–∂–∞–Ω–∏–µ..."
        )
        analysis = await analyze_meeting(transcript, lang_code)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        user_data[user_id]["analysis"] = analysis
        user_data[user_id]["transcript"] = transcript
        
        # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        await callback.message.edit_text(
            format_summary(analysis),
            reply_markup=get_topics_keyboard(analysis, user_id),
            parse_mode="Markdown"
        )
        
    except json.JSONDecodeError as e:
        print(f"JSON Error: {e}")
        await callback.message.edit_text("‚ùå –û—à–∏–±–∫–∞ –∞–Ω–∞–ª–∏–∑–∞. –ü–æ–ø—Ä–æ–±—É–π –µ—â—ë —Ä–∞–∑.")
    except Exception as e:
        print(f"Error: {type(e).__name__}: {e}")
        await callback.message.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {type(e).__name__}")
    finally:
        if file_path and os.path.exists(file_path):
            os.unlink(file_path)
@app.on_callback_query(filters.regex(r"^topic_"))
async def topic_callback(client: Client, callback: CallbackQuery):
    """–ü–æ–∫–∞–∑–∞—Ç—å –¥–µ—Ç–∞–ª–∏ —Ç–µ–º—ã"""
    
    parts = callback.data.split("_")
    user_id = int(parts[1])
    topic_idx = int(parts[2])
    
    if callback.from_user.id != user_id:
        await callback.answer("–≠—Ç–æ –Ω–µ —Ç–≤–æ–π –∑–∞–ø—Ä–æ—Å!", show_alert=True)
        return
    
    if user_id not in user_data or "analysis" not in user_data[user_id]:
        await callback.answer("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞", show_alert=True)
        return
    
    analysis = user_data[user_id]["analysis"]
    topics = analysis.get("topics", [])
    
    if topic_idx >= len(topics):
        await callback.answer("–¢–µ–º–∞ –Ω–µ –Ω–∞–π–¥–µ–Ω–∞", show_alert=True)
        return
    
    topic = topics[topic_idx]
    
    await callback.message.edit_text(
        format_topic_detail(topic, topic_idx + 1),
        reply_markup=get_back_keyboard(user_id),
        parse_mode="Markdown"
    )


@app.on_callback_query(filters.regex(r"^full_"))
async def full_callback(client: Client, callback: CallbackQuery):
    """–ü–æ–∫–∞–∑–∞—Ç—å –ø–æ–ª–Ω—ã–π –∞–Ω–∞–ª–∏–∑"""
    
    user_id = int(callback.data.split("_")[1])
    
    if callback.from_user.id != user_id:
        await callback.answer("–≠—Ç–æ –Ω–µ —Ç–≤–æ–π –∑–∞–ø—Ä–æ—Å!", show_alert=True)
        return
    
    if user_id not in user_data or "analysis" not in user_data[user_id]:
        await callback.answer("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞", show_alert=True)
        return
    
    analysis = user_data[user_id]["analysis"]
    
    await callback.message.edit_text(
        format_full_analysis(analysis),
        reply_markup=get_back_keyboard(user_id),
        parse_mode="Markdown"
    )


@app.on_callback_query(filters.regex(r"^recs_"))
async def recs_callback(client: Client, callback: CallbackQuery):
    """–ü–æ–∫–∞–∑–∞—Ç—å —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏"""
    
    user_id = int(callback.data.split("_")[1])
    
    if callback.from_user.id != user_id:
        await callback.answer("–≠—Ç–æ –Ω–µ —Ç–≤–æ–π –∑–∞–ø—Ä–æ—Å!", show_alert=True)
        return
    
    if user_id not in user_data or "analysis" not in user_data[user_id]:
        await callback.answer("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞", show_alert=True)
        return
    
    analysis = user_data[user_id]["analysis"]
    
    await callback.message.edit_text(
        format_recommendations(analysis),
        reply_markup=get_back_keyboard(user_id),
        parse_mode="Markdown"
    )


@app.on_callback_query(filters.regex(r"^back_"))
async def back_callback(client: Client, callback: CallbackQuery):
    """–í–µ—Ä–Ω—É—Ç—å—Å—è –∫ —Å–ø–∏—Å–∫—É —Ç–µ–º"""
    
    user_id = int(callback.data.split("_")[1])
    
    if callback.from_user.id != user_id:
        await callback.answer("–≠—Ç–æ –Ω–µ —Ç–≤–æ–π –∑–∞–ø—Ä–æ—Å!", show_alert=True)
        return
    
    if user_id not in user_data or "analysis" not in user_data[user_id]:
        await callback.answer("–°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞", show_alert=True)
        return
    
    analysis = user_data[user_id]["analysis"]
    
    await callback.message.edit_text(
        format_summary(analysis),
        reply_markup=get_topics_keyboard(analysis, user_id),
        parse_mode="Markdown"
    )


# ============= RUN =============
if __name__ == "__main__":
    print("Starting –¶–∏—Ñ—Ä–æ–≤–æ–π –£–º–Ω–∏–∫...")
    app.run()
